{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a set of bibtex of publications and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). \n",
    "\n",
    "The core python code is also in `pubsFromBibs.py`. \n",
    "Run either from the `markdown_generator` folder after replacing updating the publist dictionary with:\n",
    "* bib file names\n",
    "* specific venue keys based on your bib file preferences\n",
    "* any specific pre-text for specific files\n",
    "* Collection Name (future feature)\n",
    "\n",
    "TODO: Make this work with other databases of citations, \n",
    "TODO: Merge this with the existing TSV parsing solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybtex.database.input import bibtex\n",
    "import pybtex.database.input.bibtex \n",
    "from time import strptime\n",
    "import string\n",
    "import html\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: incorporate different collection types rather than a catch all publications, requires other changes to template\n",
    "publist = {\n",
    "    \"proceeding\": {\n",
    "        \"file\" : \"proceedings.bib\",\n",
    "        \"venuekey\": \"booktitle\",\n",
    "        \"venue-pretext\": \"In the proceedings of \",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"category\": \"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "        \n",
    "    },\n",
    "    \"thesis\":{\n",
    "        \"file\": \"thesis.bib\",\n",
    "        \"venuekey\" : \"school\",\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"category\": \"thesis\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "    },\n",
    "    \"journals\":{\n",
    "        \"file\": \"survey.bib\",\n",
    "        \"venuekey\" : \"journal\",\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"category\": \"survey\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "    },\n",
    "    \"preprints\":{\n",
    "        \"file\": \"preprints.bib\",\n",
    "        \"venuekey\" : \"type\",\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"category\": \"preprints\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "    } \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "# Dictionary of LaTeX-like sequences and their Unicode equivalents\n",
    "latex_to_unicode = {\n",
    "    r'{\\\\\\\"o}': 'ö',\n",
    "    r'{\\\\\\\"a}': 'ä',\n",
    "    r'{\\\\\\'a}': 'á',\n",
    "    r'{\\\\\\'e}': 'é',\n",
    "    r'{\\\\\\'i}': 'í',\n",
    "    r'{\\\\\\'o}': 'ó',\n",
    "    r'{\\\\\\'u}': 'ú',\n",
    "    r'{\\\\\\`a}': 'à',\n",
    "    r'{\\\\\\`e}': 'è',\n",
    "    r'{\\\\\\`i}': 'ì',\n",
    "    r'{\\\\\\`o}': 'ò',\n",
    "    r'{\\\\\\`u}': 'ù',\n",
    "    r'{\\\\\\^a}': 'â',\n",
    "    r'{\\\\\\^e}': 'ê',\n",
    "    r'{\\\\\\^i}': 'î',\n",
    "    r'{\\\\\\^o}': 'ô',\n",
    "    r'{\\\\\\^u}': 'û',\n",
    "    r'{\\\\\\~n}': 'ñ',\n",
    "    r'{\\\\\\~o}': 'õ'\n",
    "}\n",
    "\n",
    "# Function to replace LaTeX-like sequences with Unicode characters\n",
    "def convert_latex_to_unicode(text):\n",
    "    for latex_char, unicode_char in latex_to_unicode.items():\n",
    "        text = re.sub(latex_char, unicode_char, text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCESSFULLY PARSED gunnarsson2020learning: \" Learning a Deformable Registration Pyramid  \"\n",
      "Ultrasonic imaging;Motion segmentation;Dynamics;Time series analysis;Surgery;State-space methods;Spatiotemporal phenomena;Dynamic system;State-space models;Deep learning;Generative models;Sequential modeling;Image registration\n",
      "SUCESSFULLY PARSED gunnarsson2022unsupervised: \" Unsupervised dynamic modeling of medical image transformatio ... \"\n",
      "SUCESSFULLY PARSED gunnarsson2024online: \" Online Learning in Motion Modeling for Intra-interventional  ... \"\n",
      "SUCESSFULLY PARSED gunnarsson2021registration: \" On the Registration and Modeling of Sequential Medical Image ... \"\n",
      "SUCESSFULLY PARSED hering2022learn2reg: \" Learn2Reg: comprehensive multi-task medical image registrati ... \"\n",
      "Motion modeling, 3D reconstruction, Medical image registration, Diffusion model\n",
      "SUCESSFULLY PARSED gunnarsson2023diffusion: \" {Diffusion-Based 3D Motion Estimation from Sparse 2D Observa ... \"\n",
      "SUCESSFULLY PARSED gunnarsson2024cinemri: \" Machine learning-based 3D deformable motion modeling for MRI ... \"\n",
      "SUCESSFULLY PARSED gunnarsson2020registration: \" Registration by tracking for sequential 2D MRI  \"\n"
     ]
    }
   ],
   "source": [
    "for pubsource in publist:\n",
    "    parser = bibtex.Parser()\n",
    "    bibdata = parser.parse_file(publist[pubsource][\"file\"])\n",
    "\n",
    "    #loop through the individual references in a given bibtex file\n",
    "    for bib_id in bibdata.entries:\n",
    "        #reset default date\n",
    "        pub_year = \"1900\"\n",
    "        pub_month = \"01\"\n",
    "        pub_day = \"01\"\n",
    "        \n",
    "        b = bibdata.entries[bib_id].fields\n",
    "        \n",
    "        try:\n",
    "            pub_year = f'{b[\"year\"]}'\n",
    "\n",
    "            #todo: this hack for month and day needs some cleanup\n",
    "            if \"month\" in b.keys(): \n",
    "                if(len(b[\"month\"])<3):\n",
    "                    pub_month = \"0\"+b[\"month\"]\n",
    "                    pub_month = pub_month[-2:]\n",
    "                elif(b[\"month\"] not in range(12)):\n",
    "                    tmnth = strptime(b[\"month\"][:3],'%b').tm_mon   \n",
    "                    pub_month = \"{:02d}\".format(tmnth) \n",
    "                else:\n",
    "                    pub_month = str(b[\"month\"])\n",
    "            if \"day\" in b.keys(): \n",
    "                pub_day = str(b[\"day\"])\n",
    "\n",
    "                \n",
    "            pub_date = pub_year+\"-\"+pub_month+\"-\"+pub_day\n",
    "            \n",
    "            #strip out {} as needed (some bibtex entries that maintain formatting)\n",
    "            clean_title = b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\").replace(\" \",\"-\")    \n",
    "\n",
    "            url_slug = re.sub(\"\\\\[.*\\\\]|[^a-zA-Z0-9_-]\", \"\", clean_title)\n",
    "            url_slug = url_slug.replace(\"--\",\"-\")\n",
    "\n",
    "            md_filename = (str(pub_date) + \"-\" + url_slug + \".md\").replace(\"--\",\"-\")\n",
    "            html_filename = (str(pub_date) + \"-\" + url_slug).replace(\"--\",\"-\")\n",
    "\n",
    "            #Build Citation from text\n",
    "            citation = \"\"\n",
    "            authors = []\n",
    "            #citation authors - todo - add highlighting for primary author?\n",
    "            for author in bibdata.entries[bib_id].persons[\"author\"]:\n",
    "                if len(author.first_names) > 0:\n",
    "                    cit = author.first_names[0]+\" \"+author.last_names[0]\n",
    "                else:\n",
    "                    cit = author.last_names[0]\n",
    "                citation = citation+\" \"+cit + \", \"\n",
    "                authors.append(cit)\n",
    "\n",
    "            # = citation\n",
    "            authors = ', '.join(authors)\n",
    "            authors = convert_latex_to_unicode(authors)\n",
    "            #citation title\n",
    "            citation = convert_latex_to_unicode(citation) + \"\\\"\" + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + \".\\\"\"\n",
    "\n",
    "            #add venue logic depending on citation type\n",
    "            venue = publist[pubsource][\"venue-pretext\"]+b[publist[pubsource][\"venuekey\"]].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")\n",
    "\n",
    "            citation = citation + \" \" + html_escape(venue)\n",
    "            citation = citation + \", \" + pub_year + \".\"\n",
    "\n",
    "            \n",
    "            ## YAML variables\n",
    "            md = \"---\\ntitle: \\\"\"   + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + '\"\\n'\n",
    "\n",
    "            md += \"\"\"authors: \"\"\" + authors + '\\n'\n",
    "            \n",
    "            md += \"\"\"collection: \"\"\" +  publist[pubsource][\"collection\"][\"name\"]\n",
    "\n",
    "            md += \"\"\"\\ncategory: \"\"\" +  publist[pubsource][\"collection\"][\"category\"]\n",
    "\n",
    "            md += \"\"\"\\npermalink: \"\"\" + publist[pubsource][\"collection\"][\"permalink\"]  + html_filename\n",
    "\n",
    "            if 'abstract' in b.keys():\n",
    "                md += \"\"\"\\nabstract: \"\"\" + html_escape(b[\"abstract\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\").replace(\":\",\";\").replace(\"$\",\"\"))\n",
    "\n",
    "            if 'keywords' in b.keys():\n",
    "                md += \"\"\"\\nkeywords: \"\"\" + html_escape(b[\"keywords\"].replace(\";\",\",\"))\n",
    "                print(b[\"keywords\"])\n",
    "            \n",
    "            note = False\n",
    "            if \"note\" in b.keys():\n",
    "                if len(str(b[\"note\"])) > 5:\n",
    "                    md += \"\\nexcerpt: '\" + html_escape(b[\"note\"]) + \"'\"\n",
    "                    note = True\n",
    "\n",
    "            md += \"\\ndate: \" + str(pub_date) \n",
    "\n",
    "            md += \"\\nvenue: '\" + html_escape(venue) + \"'\"\n",
    "            \n",
    "            url = False\n",
    "            if \"url\" in b.keys():\n",
    "                if len(str(b[\"url\"])) > 5:\n",
    "                    md += \"\\npaperurl: '\" + b[\"url\"] + \"'\"\n",
    "                    url = True\n",
    "\n",
    "            code = False\n",
    "            if \"code\" in b.keys():\n",
    "                if len(str(b[\"code\"])) > 5:\n",
    "                    md += \"\\ncodeurl: '\" + b[\"code\"] + \"'\"\n",
    "                    code = True\n",
    "\n",
    "            md += \"\\ncitation: '\" + html_escape(citation) + \"'\"\n",
    "\n",
    "            md += \"\\n---\"\n",
    "\n",
    "            \n",
    "            ## Markdown description for individual page\n",
    "            if note:\n",
    "                md += \"\\n\" + html_escape(b[\"note\"]) + \"\\n\"\n",
    "\n",
    "            '''\n",
    "            if url:\n",
    "                md += \"\\n[Paper](\" + b[\"url\"] + \"){:target=\\\"_blank\\\"}\" \n",
    "            #else:\n",
    "            #    md += \"\\nUse [Google Scholar](https://scholar.google.com/scholar?q=\"+html.escape(clean_title.replace(\"-\",\"+\"))+\"){:target=\\\"_blank\\\"} for full citation\"\n",
    "\n",
    "            if code:\n",
    "                md += \" [Code](\" + b[\"code\"] + \"){:target=\\\"_blank\\\"}\\n\" \n",
    "            '''\n",
    "            md_filename = os.path.basename(md_filename)\n",
    "\n",
    "            with open(\"../_publications/\" + md_filename, 'w', encoding=\"utf-8\") as f:\n",
    "                f.write(md)\n",
    "            print(f'SUCESSFULLY PARSED {bib_id}: \\\"', b[\"title\"][:60],\"...\"*(len(b['title'])>60),\"\\\"\")\n",
    "        # field may not exist for a reference\n",
    "        except KeyError as e:\n",
    "            print(f'WARNING Missing Expected Field {e} from entry {bib_id}: \\\"', b[\"title\"][:30],\"...\"*(len(b['title'])>30),\"\\\"\")\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Our anatomy is in constant motion. With modern MR imaging it is possible to record this motion in real-time during an ongoing radiation therapy session. In this paper we present an image registration method that exploits the sequential nature of 2D MR images to estimate the corresponding displacement field. The method employs several discriminative correlation filters that independently track specific points. Together with a sparse-to-dense interpolation scheme we can then estimate of the displacement field. The discriminative correlation filters are trained online, and our method is modality agnostic. For the interpolation scheme we use a neural network with normalized convolutions that is trained using synthetic diffeomorphic displacement fields. The method is evaluated on a segmented cardiac dataset and when compared to two conventional methods we observe an improved performance. This improvement is especially pronounced when it comes to the detection of larger motions of small objects.'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_escape(b[\"abstract\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "title: \"Registration by tracking for sequential 2D MRI\"\n",
      "authors: Niklas Gunnarsson, Jens Sjölund, Thomas Schön\n",
      "collection: publications\n",
      "category: preprints\n",
      "permalink: /publication/2020-01-01-Registration-by-tracking-for-sequential-2D-MRI\n",
      "abstract: Our anatomy is in constant motion. With modern MR imaging it is possible to record this motion in real-time during an ongoing radiation therapy session. In this paper we present an image registration method that exploits the sequential nature of 2D MR images to estimate the corresponding displacement field. The method employs several discriminative correlation filters that independently track specific points. Together with a sparse-to-dense interpolation scheme we can then estimate of the displacement field. The discriminative correlation filters are trained online, and our method is modality agnostic. For the interpolation scheme we use a neural network with normalized convolutions that is trained using synthetic diffeomorphic displacement fields. The method is evaluated on a segmented cardiac dataset and when compared to two conventional methods we observe an improved performance. This improvement is especially pronounced when it comes to the detection of larger motions of small objects.\n",
      "date: 2020-01-01\n",
      "venue: 'Preprint'\n",
      "paperurl: 'https://arxiv.org/abs/2003.10819'\n",
      "citation: ' Niklas Gunnarsson,  Jens Sjölund,  Thomas Schön, &quot;Registration by tracking for sequential 2D MRI.&quot; Preprint, 2020.'\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Our anatomy is in constant motion. With modern MR imaging it is possible to record this motion in real-time during an ongoing radiation therapy session. In this paper we present an image registration method that exploits the sequential nature of 2D MR images to estimate the corresponding displacement field. The method employs several discriminative correlation filters that independently track specific points. Together with a sparse-to-dense interpolation scheme we can then estimate of the displacement field. The discriminative correlation filters are trained online, and our method is modality agnostic. For the interpolation scheme we use a neural network with normalized convolutions that is trained using synthetic diffeomorphic displacement fields. The method is evaluated on a segmented cardiac dataset and when compared to two conventional methods we observe an improved performance. This improvement is especially pronounced when it comes to the detection of larger motions of small objects.'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[\"abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thomas Sch{\\\\\"o}n'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
